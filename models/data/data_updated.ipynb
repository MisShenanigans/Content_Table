{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to download\n",
    "\n",
    "# import kagglehub\n",
    "# path = kagglehub.dataset_download(\"marlesson/myanimelist-dataset-animes-profiles-reviews\")\n",
    "# print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "animes_df = pd.read_csv(\"original_data/animes.csv\")\n",
    "profiles_df = pd.read_csv(\"original_data/profiles.csv\")\n",
    "reviews_df = pd.read_csv(\"original_data/reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep uid and title columns, change uid to a_id\n",
    "cleared_anime_df = animes_df[[\"uid\", \"title\"]]\n",
    "cleared_anime_df.rename(columns={\"uid\": \"a_id\"}, inplace=True)\n",
    "\n",
    "# keep profile column, make a new column named u_id, make profile unique, keep u_id as index\n",
    "cleared_profile_df = profiles_df[[\"profile\"]]\n",
    "cleared_profile_df = cleared_profile_df.drop_duplicates(subset='profile')\n",
    "cleared_profile_df['u_id'] = range(0, len(cleared_profile_df))\n",
    "\n",
    "\n",
    "# keep profile anime_uid and score columns, change anime_uid to a_id\n",
    "cleared_reviews_df = reviews_df[[\"profile\", \"anime_uid\", \"score\"]]\n",
    "cleared_reviews_df.rename(columns={\"anime_uid\": \"a_id\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge cleared_reviews_df with cleared_profile_df using profile column\n",
    "merged_review_profile_df = cleared_reviews_df.merge(cleared_profile_df, on=\"profile\")    \n",
    "\n",
    "# merge cleared_anime_df with merged_review_profile_df using a_id column\n",
    "merged_review_profile_anime_df = merged_review_profile_df.merge(cleared_anime_df, on=\"a_id\")\n",
    "\n",
    "# at some point, we create duplicates. Removes duplicates\n",
    "merged_review_profile_anime_df = merged_review_profile_anime_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save anime id and genre for reco\n",
    "anime_id_to_genre = animes_df[[\"uid\", \"genre\"]]\n",
    "anime_id_to_genre.rename(columns={\"uid\": \"a_id\"}, inplace=True) \n",
    "anime_id_to_genre.to_csv(\"data/anime_id_to_genre.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder columns\n",
    "final_df = merged_review_profile_anime_df[[\"u_id\", \"a_id\", \"profile\", \"title\", \"score\"]]\n",
    "\n",
    "# create id, and set it as index\n",
    "final_df[\"id\"] = range(0, len(final_df))\n",
    "final_df.set_index(\"id\", inplace=True)\n",
    "\n",
    "# remove index name\n",
    "final_df.index.name = None\n",
    "\n",
    "# save the final data\n",
    "final_df.to_csv(\"data/final_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduceMatrixSize(df, u_review_count, a_review_count):\n",
    "    \n",
    "    # only keep the users with at least u_review_count reviews\n",
    "    df = df[df.groupby('u_id')['u_id'].transform('count') >= u_review_count]\n",
    "\n",
    "    # only keep the animes with at least a_review_count reviews\n",
    "    df = df[df.groupby('a_id')['a_id'].transform('count') >= a_review_count]\n",
    "    print(f\"Reduced matrix size to {df[\"u_id\"].nunique()} users and {df[\"a_id\"].nunique()} animes\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced matrix size to 144 users and 131 animes\n"
     ]
    }
   ],
   "source": [
    "new_df = reduceMatrixSize(final_df, 50, 14) # 100x100\n",
    "new_df.to_csv(\"data/100x100.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced matrix size to 39 users and 87 animes\n"
     ]
    }
   ],
   "source": [
    "new_df = reduceMatrixSize(final_df, 100, 8) # 10x10\n",
    "new_df.to_csv(\"data/10x10.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced matrix size to 145 users and 138 animes\n"
     ]
    }
   ],
   "source": [
    "final_df = pd.read_csv(\"data/final_data.csv\")\n",
    "hundred_df = pd.read_csv(\"data/100x100.csv\")\n",
    "\n",
    "result = final_df.merge(hundred_df, how=\"left\", indicator=True)\n",
    "result = result[result['_merge'] == 'left_only'].drop('_merge', axis=1)\n",
    "\n",
    "second_hundred_df = reduceMatrixSize(result, 44, 10) # 100x100_2 \n",
    "second_hundred_df.to_csv(\"data/100x100_2.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
